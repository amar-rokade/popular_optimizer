{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('myweb')",
   "display_name": "Python 3.8.2 64-bit ('myweb')",
   "metadata": {
    "interpreter": {
     "hash": "eb4936cc236732cdfb37cb3f6ac5012c34fedb46f1fc1eb5e99aacff659654a6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#IMPORT ALL PRE BUILD FUNCTION \n",
    "from func import *\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from momentum import *\n",
    "from RMSprop import *\n",
    "from adam import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf1 = h5py.File('/pythonfile/popular_optimizer/train.h5','r')  #READ THE DATASETS\n",
    "X_train = hf1.get('X_train')     #GET THE X TRAINING DATASETS\n",
    "Y_train = hf1.get('Y_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X_train (259, 12288)  and  Y_train (259, 1)\n"
     ]
    }
   ],
   "source": [
    "#flatten the array and normalize \n",
    "X_train = np.reshape(X_train,(X_train.shape[0],-1))  #FLATTEN   (209, 64 *64 * 3)\n",
    "X_train = preprocessing.normalize(X_train)           #NORMALIZING THE DATASETS\n",
    "\n",
    "Y_train = np.reshape(Y_train,(Y_train.shape[0],1))                # MAKING SURE IT IS IN CORRECT SHAPE\n",
    "\n",
    "print(\"Shape of X_train {}  and  Y_train {}\".format(X_train.shape,Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,Y,learning_rate,num_iter,hidden_size,keep_prob,optimizer):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    \n",
    "    if optimizer == 'Momentum':\n",
    "        v = initilization_moment(params)\n",
    "\n",
    "    elif optimizer == 'Rmsprop':\n",
    "        s = initilization_RMS(params)\n",
    "\n",
    "    elif optimizer == 'adam' :\n",
    "        v,s = initilization_Adam(params)\n",
    "\n",
    "    for i in range(1,num_iter):\n",
    "        MiniBatches = RandomMiniBatches(X, Y, 64)\n",
    "        p , q = MiniBatches[2]\n",
    "        for MiniBatch in MiniBatches:\n",
    "\n",
    "            (MiniBatch_X, MiniBatch_Y) = MiniBatch\n",
    "\n",
    "            cache, A = model_forward(MiniBatch_X, params, L,keep_prob)\n",
    "            cost = cost_f(A, MiniBatch_Y) \n",
    "            grad = backward(MiniBatch_X, MiniBatch_Y, params, cache, L,keep_prob)\n",
    "\n",
    "            if optimizer == 'Momentum':\n",
    "                params = update_params_with_momentum(params, grad, v, beta=0.9,learning_rate=learning_rate)\n",
    "\n",
    "            elif optimizer == 'Rmsprop':\n",
    "               params = update_params_with_RMS(params, grad, s, beta=0.9,learning_rate=learning_rate)\n",
    "\n",
    "            elif optimizer == 'Adam' :\n",
    "                params = update_params_with_Adam(params, grad,v, s, beta1=0.9,beta2=0.999,learning_rate=learning_rate,t=i)\n",
    "\n",
    "           \n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('cost of iteration______{}__________{}'.format(i,cost))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration______500__________0.026226994301552467\n",
      "train_accuracy------------ 0.9691119691119691\n"
     ]
    }
   ],
   "source": [
    "params = model(X_train, Y_train, learning_rate = 0.009,\n",
    "               num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='Adam')\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration______100__________0.6465357839100283\n",
      "cost of iteration______200__________0.14667287714940405\n",
      "cost of iteration______300__________0.5569837722631358\n",
      "cost of iteration______400__________0.4387814209192945\n",
      "cost of iteration______500__________0.2569025476023223\n",
      "cost of iteration______600__________0.4815562414002521\n",
      "cost of iteration______700__________0.4413088519845014\n",
      "cost of iteration______800__________0.21030633214482936\n",
      "cost of iteration______900__________0.14359594341871262\n",
      "train_accuracy------------ 0.8996138996138996\n"
     ]
    }
   ],
   "source": [
    "params = model(X_train, Y_train, learning_rate = 0.009,\n",
    "               num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='Momentum')\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration______100__________0.7213054226936804\n",
      "cost of iteration______200__________0.7288887939688129\n",
      "cost of iteration______300__________0.6838691968163619\n",
      "cost of iteration______400__________0.6796987230047025\n",
      "cost of iteration______500__________0.6776842785109825\n",
      "cost of iteration______600__________0.7221688378838073\n",
      "cost of iteration______700__________0.685678944881559\n",
      "cost of iteration______800__________0.7322927440436902\n",
      "cost of iteration______900__________0.6919312289405452\n",
      "train_accuracy------------ 0.4555984555984556\n"
     ]
    }
   ],
   "source": [
    "params = model(X_train, Y_train, learning_rate = 0.009,\n",
    "               num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='RMSprop')\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simple_gradient_descent(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "\n",
    "    for i in range(1,num_iter):\n",
    "\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params(params, grad, learning_rate, L)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration________________ 20\n",
      "0.6196480314939471\n",
      "cost of iteration________________ 40\n",
      "0.609287022014639\n",
      "cost of iteration________________ 60\n",
      "0.585299990570172\n",
      "cost of iteration________________ 80\n",
      "0.5867410369882348\n",
      "cost of iteration________________ 100\n",
      "0.5573366384458787\n",
      "cost of iteration________________ 120\n",
      "0.5481453600680758\n",
      "cost of iteration________________ 140\n",
      "0.540081161976517\n",
      "cost of iteration________________ 160\n",
      "0.5256660204617498\n",
      "cost of iteration________________ 180\n",
      "0.5357365574912608\n",
      "train_accuracy------------ 0.8086124401913876\n"
     ]
    }
   ],
   "source": [
    "params = model_simple_gradient_descent(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_momentum_optimizer(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    v = initilization_moment(params)\n",
    "    for i in range(1,num_iter):\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params_with_momentum(params, grad, v, beta=0.9,learning_rate=learning_rate)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration________________ 20\n",
      "0.6144856943253116\n",
      "cost of iteration________________ 40\n",
      "0.5715780411001979\n",
      "cost of iteration________________ 60\n",
      "0.5438768046959095\n",
      "cost of iteration________________ 80\n",
      "0.511577767817021\n",
      "cost of iteration________________ 100\n",
      "0.49070902690418217\n",
      "cost of iteration________________ 120\n",
      "0.47877285620702753\n",
      "cost of iteration________________ 140\n",
      "0.44634502661480824\n",
      "cost of iteration________________ 160\n",
      "0.42525388795193764\n",
      "cost of iteration________________ 180\n",
      "0.4168274516521236\n",
      "train_accuracy------------ 0.8516746411483254\n"
     ]
    }
   ],
   "source": [
    "params = model_momentum_optimizer(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_RMSprop_optimizer(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    s = initilization_RMS(params)\n",
    "    for i in range(1,num_iter):\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params_with_RMS(params, grad, s, beta=0.9,learning_rate=learning_rate)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration________________ 20\n",
      "0.6426505857791115\n",
      "cost of iteration________________ 40\n",
      "0.6439747377347322\n",
      "cost of iteration________________ 60\n",
      "0.6419580033453186\n",
      "cost of iteration________________ 80\n",
      "0.6420333441950518\n",
      "cost of iteration________________ 100\n",
      "0.6421989031650565\n",
      "cost of iteration________________ 120\n",
      "0.6421855100610335\n",
      "cost of iteration________________ 140\n",
      "0.6422206926041393\n",
      "cost of iteration________________ 160\n",
      "0.6424180941588862\n",
      "cost of iteration________________ 180\n",
      "0.6421493894176203\n",
      "train_accuracy------------ 0.6555023923444976\n"
     ]
    }
   ],
   "source": [
    "params = model_RMSprop_optimizer(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Adam_optimizer(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    v,s = initilization_Adam(params)\n",
    "    for i in range(1,num_iter):\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params_with_Adam(params, grad,v, s, beta1=0.9,beta2=0.999,learning_rate=learning_rate,t=i)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration________________ 20\n",
      "0.6917068244512788\n",
      "cost of iteration________________ 40\n",
      "0.6635906969014986\n",
      "cost of iteration________________ 60\n",
      "0.6446188405962355\n",
      "cost of iteration________________ 80\n",
      "0.6442435515110979\n",
      "cost of iteration________________ 100\n",
      "0.6440080034339223\n",
      "cost of iteration________________ 120\n",
      "0.6439739338702876\n",
      "cost of iteration________________ 140\n",
      "0.643974447999584\n",
      "cost of iteration________________ 160\n",
      "0.6439738156279745\n",
      "cost of iteration________________ 180\n",
      "0.6439737387058295\n"
     ]
    }
   ],
   "source": [
    "params = model_Adam_optimizer(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_accuracy------------ 0.6555023923444976\n"
     ]
    }
   ],
   "source": [
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}