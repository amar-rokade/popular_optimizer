{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('myweb')",
   "display_name": "Python 3.8.2 64-bit ('myweb')",
   "metadata": {
    "interpreter": {
     "hash": "eb4936cc236732cdfb37cb3f6ac5012c34fedb46f1fc1eb5e99aacff659654a6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#IMPORT ALL PRE BUILD FUNCTION \n",
    "from func import *\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from momentum import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X_train (209, 64, 64, 3)  and  Y_train (209,)\n"
     ]
    }
   ],
   "source": [
    "#PATH SHOULD BE   YOUR_FOLDER_PATH/popular_optimizer/datasets/train_catvnoncat.h5\n",
    "hf1 = h5py.File('/pythonfile/popular_optimizer/datasets/train_catvnoncat.h5','r')  #READ THE DATASETS\n",
    "X_train = hf1.get('train_set_x')     #GET THE X TRAINING DATASETS\n",
    "Y_train = hf1.get('train_set_y')     #GET Y LABEL \n",
    "\n",
    "print(\"Shape of X_train {}  and  Y_train {}\".format(X_train.shape,Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X_train (209, 12288)  and  Y_train (209, 1)\n"
     ]
    }
   ],
   "source": [
    "#flatten the array and normalize \n",
    "X_train = np.reshape(X_train,(X_train.shape[0],-1))  #FLATTEN   (209, 64 *64 * 3)\n",
    "X_train = preprocessing.normalize(X_train)           #NORMALIZING THE DATASETS\n",
    "\n",
    "Y_train = np.reshape(Y_train,(Y_train.shape[0],1))                # MAKING SURE IT IS IN CORRECT SHAPE\n",
    "\n",
    "print(\"Shape of X_train {}  and  Y_train {}\".format(X_train.shape,Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simple_gradient_descent(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "\n",
    "    for i in range(1,num_iter):\n",
    "\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params(params, grad, learning_rate, L)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration________________ 20\n",
      "0.6196480314939471\n",
      "cost of iteration________________ 40\n",
      "0.609287022014639\n",
      "cost of iteration________________ 60\n",
      "0.585299990570172\n",
      "cost of iteration________________ 80\n",
      "0.5867410369882348\n",
      "cost of iteration________________ 100\n",
      "0.5573366384458787\n",
      "cost of iteration________________ 120\n",
      "0.5481453600680758\n",
      "cost of iteration________________ 140\n",
      "0.540081161976517\n",
      "cost of iteration________________ 160\n",
      "0.5256660204617498\n",
      "cost of iteration________________ 180\n",
      "0.5357365574912608\n",
      "train_accuracy------------ 0.8086124401913876\n"
     ]
    }
   ],
   "source": [
    "params = model_simple_gradient_descent(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_momentum_optimizer(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    v = initilization_moment(params)\n",
    "    for i in range(1,num_iter):\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params_with_momentum(params, grad, v, beta=0.9,learning_rate=learning_rate)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration________________ 20\n",
      "0.6144856943253116\n",
      "cost of iteration________________ 40\n",
      "0.5715780411001979\n",
      "cost of iteration________________ 60\n",
      "0.5438768046959095\n",
      "cost of iteration________________ 80\n",
      "0.511577767817021\n",
      "cost of iteration________________ 100\n",
      "0.49070902690418217\n",
      "cost of iteration________________ 120\n",
      "0.47877285620702753\n",
      "cost of iteration________________ 140\n",
      "0.44634502661480824\n",
      "cost of iteration________________ 160\n",
      "0.42525388795193764\n",
      "cost of iteration________________ 180\n",
      "0.4168274516521236\n",
      "train_accuracy------------ 0.8516746411483254\n"
     ]
    }
   ],
   "source": [
    "params = model_momentum_optimizer(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_RMSprop_optimizer(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    v = initilization_moment(params)\n",
    "    for i in range(1,num_iter):\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params_with_RMS(params, grad, v, beta=0.9,learning_rate=learning_rate)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model_RMSprop_optimizer(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  }
 ]
}