{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('myweb')",
   "display_name": "Python 3.8.2 64-bit ('myweb')",
   "metadata": {
    "interpreter": {
     "hash": "eb4936cc236732cdfb37cb3f6ac5012c34fedb46f1fc1eb5e99aacff659654a6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#IMPORT ALL PRE BUILD FUNCTION \n",
    "from func import *\n",
    "from momentum import *\n",
    "from RMSprop import *\n",
    "from adam import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X_train (259, 12288)  and  Y_train (259, 1)\n"
     ]
    }
   ],
   "source": [
    "hf1 = h5py.File('/pythonfile/popular_optimizer/train_datasets.h5','r')  #READ THE DATASETS\n",
    "X_train = hf1.get('X_train')     #GET THE X TRAINING DATASETS\n",
    "Y_train = hf1.get('Y_train')\n",
    "#flatten the array and normalize \n",
    "X_train = np.reshape(X_train,(X_train.shape[0],-1))  #FLATTEN   (209, 64 *64 * 3)\n",
    "X_train = preprocessing.normalize(X_train)           #NORMALIZING THE DATASETS\n",
    "\n",
    "Y_train = np.reshape(Y_train,(Y_train.shape[0],1))                # MAKING SURE IT IS IN CORRECT SHAPE\n",
    "\n",
    "print(\"Shape of X_train {}  and  Y_train {}\".format(X_train.shape,Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,Y,learning_rate,num_iter,hidden_size,keep_prob,optimizer):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    costs = []\n",
    "    itr  = []\n",
    "\n",
    "    if optimizer == 'momentum':\n",
    "        v = initilization_moment(params)\n",
    "\n",
    "    elif optimizer == 'rmsprop':\n",
    "        s = initilization_RMS(params)\n",
    "\n",
    "    elif optimizer == 'adam' :\n",
    "        v,s = initilization_Adam(params)\n",
    "\n",
    "    for i in range(1,num_iter):\n",
    "        MiniBatches = RandomMiniBatches(X, Y, 32)   # GET RAMDOMLY MINIBATCHES\n",
    "        p , q = MiniBatches[2]\n",
    "        for MiniBatch in MiniBatches:               #LOOP FOR MINIBATCHES\n",
    "\n",
    "            (MiniBatch_X, MiniBatch_Y) = MiniBatch\n",
    "\n",
    "            cache, A = model_forward(MiniBatch_X, params, L,keep_prob)     #FORWARD PROPOGATIONS\n",
    "            cost = cost_f(A, MiniBatch_Y)                                  #COST FUNCTION\n",
    "            grad = backward(MiniBatch_X, MiniBatch_Y, params, cache, L,keep_prob) #BACKWARD PROPAGATION \n",
    "\n",
    "            if optimizer == 'momentum':\n",
    "                params = update_params_with_momentum(params, grad, v, beta=0.9,learning_rate=learning_rate)\n",
    "\n",
    "            elif optimizer == 'rmsprop':\n",
    "               params = update_params_with_RMS(params, grad, s, beta=0.9,learning_rate=learning_rate)\n",
    "\n",
    "            elif optimizer == 'adam' :\n",
    "                params = update_params_with_Adam(params, grad,v, s, beta1=0.9,beta2=0.999,  learning_rate=learning_rate,t=i)                                         #UPDATE PARAMETERS\n",
    "            elif optimizer == \"minibatch\":\n",
    "                params = update_params(params, grad,learning_rate=learning_rate) \n",
    "\n",
    "           \n",
    "        \n",
    "        if i%10 == 0:\n",
    "            costs.append(cost)\n",
    "            itr.append(i)\n",
    "            if i % 100 == 0 :\n",
    "                print('cost of iteration______{}______{}'.format(i,cost))\n",
    "    return params,costs,itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration______100______0.35302967575683797\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-12f66358a9aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m params, cost_sgd,itr = model(X_train, Y_train, learning_rate = 0.01,\n\u001b[0m\u001b[0;32m      2\u001b[0m                num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='minibatch')\n\u001b[0;32m      3\u001b[0m \u001b[0mY_train_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_accuracy------------'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-f0e2c486632b>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X, Y, learning_rate, num_iter, hidden_size, keep_prob, optimizer)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mMiniBatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMiniBatch_Y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMiniBatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMiniBatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m#FORWARD PROPOGATIONS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMiniBatch_Y\u001b[0m\u001b[1;33m)\u001b[0m                                  \u001b[1;31m#COST FUNCTION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMiniBatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMiniBatch_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#BACKWARD PROPAGATION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\pythonfile\\popular_optimizer\\func.py\u001b[0m in \u001b[0;36mmodel_forward\u001b[1;34m(X, params, L, keep_prob)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'D'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\pythonfile\\popular_optimizer\\func.py\u001b[0m in \u001b[0;36mforward_activation\u001b[1;34m(A_prev, w, b, activation)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m#forward_propagations-----------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params, cost_sgd,itr = model(X_train, Y_train, learning_rate = 0.01,\n",
    "               num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='minibatch')\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params,cost_momentum, itr = model(X_train, Y_train, learning_rate = 0.01,\n",
    "               num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='momentum')\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params,cost_rms,itr = model(X_train, Y_train, learning_rate = 0.01,\n",
    "               num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='rmsprop')\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params,cost_adam, itr = model(X_train, Y_train, learning_rate = 0.01,\n",
    "               num_iter=1000, hidden_size=[100, 1],keep_prob=1,optimizer='adam')\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fn(itr,cost_momentum,cost_rms,cost_adam,cost_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}