{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('myweb')",
   "display_name": "Python 3.8.2 64-bit ('myweb')",
   "metadata": {
    "interpreter": {
     "hash": "eb4936cc236732cdfb37cb3f6ac5012c34fedb46f1fc1eb5e99aacff659654a6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn import preprocessing\n",
    "#IMPORT ALL PRE BUILD FUNCTION \n",
    "from func import *\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from momentum import update_params_with_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X_train (209, 64, 64, 3)  and  Y_train (209,)\n"
     ]
    }
   ],
   "source": [
    "#PATH SHOULD BE   YOUR_FOLDER_PATH/popular_optimizer/datasets/train_catvnoncat.h5\n",
    "hf1 = h5py.File('/pythonfile/popular_optimizer/datasets/train_catvnoncat.h5','r')  #READ THE DATASETS\n",
    "X_train = hf1.get('train_set_x')     #GET THE X TRAINING DATASETS\n",
    "Y_train = hf1.get('train_set_y')     #GET Y LABEL \n",
    "\n",
    "print(\"Shape of X_train {}  and  Y_train {}\".format(X_train.shape,Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of X_train (209, 12288)  and  Y_train (209, 1)\n"
     ]
    }
   ],
   "source": [
    "#flatten the array and normalize \n",
    "X_train = np.reshape(X_train,(X_train.shape[0],-1))  #FLATTEN   (209, 64 *64 * 3)\n",
    "X_train = preprocessing.normalize(X_train)           #NORMALIZING THE DATASETS\n",
    "\n",
    "Y_train = np.reshape(Y_train,(Y_train.shape[0],1))                # MAKING SURE IT IS IN CORRECT SHAPE\n",
    "\n",
    "print(\"Shape of X_train {}  and  Y_train {}\".format(X_train.shape,Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simple_gradient_descent(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "\n",
    "    for i in range(1,num_iter):\n",
    "\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params(params, grad, learning_rate, L)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cost of iteration________________ 20\n",
      "0.6168433550374998\n",
      "cost of iteration________________ 40\n",
      "0.6100245970313071\n",
      "cost of iteration________________ 60\n",
      "0.5829424468261764\n",
      "cost of iteration________________ 80\n",
      "0.5687213202657719\n",
      "cost of iteration________________ 100\n",
      "0.5596251854219648\n",
      "cost of iteration________________ 120\n",
      "0.5596750289027372\n",
      "cost of iteration________________ 140\n",
      "0.5695956625632899\n",
      "cost of iteration________________ 160\n",
      "0.5353576834148448\n",
      "cost of iteration________________ 180\n",
      "0.5279714359260345\n",
      "train_accuracy------------ 0.784688995215311\n"
     ]
    }
   ],
   "source": [
    "params = model_simple_gradient_descent(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_momentum_optimizer(X,Y,learning_rate,num_iter,hidden_size,keep_prob):\n",
    "    L = len(hidden_size)\n",
    "    params = initilization(X.shape[1], hidden_size)\n",
    "    # v = pedding\n",
    "    for i in range(1,num_iter):\n",
    "\n",
    "        cache, A = model_forward(X, params, L,keep_prob)\n",
    "        cost = cost_f(A, Y)\n",
    "        grad = backward(X, Y, params, cache, L,keep_prob)\n",
    "        params = update_params_with_momentum(params, grads, v, beta=0.9, learning_rate)\n",
    "        if i%20 == 0:\n",
    "            print('cost of iteration________________', i)\n",
    "            print(cost)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "update_params_with_momentum() missing 1 required positional argument: 'learning_rate'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6a024b3cf7e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m params = model_momentum_optimizer(X_train, Y_train, learning_rate = 0.09,\n\u001b[0m\u001b[0;32m      2\u001b[0m                num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n\u001b[0;32m      3\u001b[0m \u001b[0mY_train_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_accuracy------------'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-1911b09e8b7e>\u001b[0m in \u001b[0;36mmodel_momentum_optimizer\u001b[1;34m(X, Y, learning_rate, num_iter, hidden_size, keep_prob)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcost_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_params_with_momentum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cost of iteration________________'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: update_params_with_momentum() missing 1 required positional argument: 'learning_rate'"
     ]
    }
   ],
   "source": [
    "params = model_momentum_optimizer(X_train, Y_train, learning_rate = 0.09,\n",
    "               num_iter=200, hidden_size=[100, 1],keep_prob=0.5)\n",
    "Y_train_pre = predict(X_train, params, 2)\n",
    "print('train_accuracy------------', accuracy_score(Y_train_pre, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}